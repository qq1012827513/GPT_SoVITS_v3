{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qq1012827513/GPT_SoVITS_v3/blob/main/GPT_SoVITS_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LENDan0wB16N",
        "outputId": "20938f5d-a038-47b4-9ce0-88609e5044f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n",
            "fatal: destination path 'GPT-SoVITS-v3' already exists and is not an empty directory.\n",
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20: cannot open shared object file: No such file or directory)\n",
            "/usr/local/lib/python3.9/site-packages/conda/base/context.py:201: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
            "\n",
            "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
            "\n",
            "  conda config --add channels defaults\n",
            "\n",
            "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
            "\n",
            "  deprecated.topic(\n",
            "\n",
            "CondaValueError: You have chosen a non-default solver backend (libmamba) but it was not recognized. Choose one of: classic\n",
            "\n",
            "/content/GPT-SoVITS-v3\n",
            "Error while loading conda entry point: conda-libmamba-solver (libarchive.so.20: cannot open shared object file: No such file or directory)\n",
            "/usr/local/lib/python3.9/site-packages/conda/base/context.py:201: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
            "\n",
            "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
            "\n",
            "  conda config --add channels defaults\n",
            "\n",
            "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
            "\n",
            "  deprecated.topic(\n",
            "\n",
            "CondaValueError: You have chosen a non-default solver backend (libmamba) but it was not recognized. Choose one of: classic\n",
            "\n",
            "Ignoring onnxruntime: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Ignoring opencc: markers 'sys_platform != \"linux\"' don't match your environment\n",
            "Requirement already satisfied: numpy==1.23.4 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.19.0)\n",
            "Requirement already satisfied: librosa==0.9.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.9.2)\n",
            "Requirement already satisfied: numba==0.56.4 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.56.4)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (2.5.0.post0)\n",
            "Requirement already satisfied: gradio<=4.24.0,>=4.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (4.24.0)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.19.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (4.67.1)\n",
            "Requirement already satisfied: funasr==1.0.27 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (1.0.27)\n",
            "Requirement already satisfied: cn2an in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (0.5.23)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (0.53.0)\n",
            "Requirement already satisfied: pyopenjtalk>=0.3.4 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (0.4.0)\n",
            "Requirement already satisfied: g2p_en in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (2.1.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (2.6.0)\n",
            "Requirement already satisfied: modelscope==1.10.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (1.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 19)) (0.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (4.49.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (5.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (7.0.0)\n",
            "Requirement already satisfied: jieba_fast in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 24)) (0.53)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 25)) (0.42.1)\n",
            "Requirement already satisfied: split-lang in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 26)) (2.1.0)\n",
            "Requirement already satisfied: Faster_Whisper in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 27)) (1.1.1)\n",
            "Requirement already satisfied: wordsegment in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 28)) (1.3.1)\n",
            "Requirement already satisfied: rotary_embedding_torch in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 29)) (0.8.6)\n",
            "Requirement already satisfied: ToJyutping in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 30)) (3.2.0)\n",
            "Requirement already satisfied: g2pk2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 31)) (0.0.3)\n",
            "Requirement already satisfied: ko_pron in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 32)) (1.3)\n",
            "Requirement already satisfied: opencc==1.1.1 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 34)) (1.1.1)\n",
            "Requirement already satisfied: python_mecab_ko in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 35)) (1.3.7)\n",
            "Requirement already satisfied: fastapi<0.112.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 36)) (0.112.1)\n",
            "Requirement already satisfied: x_transformers in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 37)) (2.1.12)\n",
            "Requirement already satisfied: torchmetrics==1.5 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 38)) (1.5.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (5.2.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.4.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/site-packages (from numba==0.56.4->-r requirements.txt (line 5)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from numba==0.56.4->-r requirements.txt (line 5)) (68.2.2)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.4.1)\n",
            "Requirement already satisfied: kaldiio>=2.17.0 in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (2.18.1)\n",
            "Requirement already satisfied: torch-complex in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.4.4)\n",
            "Requirement already satisfied: pytorch-wpe in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.0.1)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: oss2 in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (2.19.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.5.7)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (0.4.0)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (1.3.2)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (2.6.2.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.9/site-packages (from funasr==1.0.27->-r requirements.txt (line 12)) (20240930)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (25.1.0)\n",
            "Requirement already satisfied: datasets>=2.14.5 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (3.3.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (0.8.1)\n",
            "Requirement already satisfied: filelock>=3.3.0 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (3.17.0)\n",
            "Requirement already satisfied: gast>=0.2.2 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (0.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.2.3)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (10.4.0)\n",
            "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (19.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.32.3)\n",
            "Requirement already satisfied: simplejson>=3.3.0 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (3.20.1)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.4.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (1.26.18)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (0.43.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.9/site-packages (from torchmetrics==1.5->-r requirements.txt (line 38)) (2.6.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.9/site-packages (from torchmetrics==1.5->-r requirements.txt (line 38)) (0.14.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (6.30.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard->-r requirements.txt (line 3)) (3.1.3)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.9/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 6)) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/site-packages (from pytorch-lightning->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==0.14.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.29.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.9.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.10.15)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.9.10)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.9 in /usr/local/lib/python3.9/site-packages (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.15.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.9/site-packages (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.34.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.9/site-packages (from gradio-client==0.14.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (11.0.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/site-packages (from ffmpeg-python->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/site-packages (from onnxruntime-gpu->-r requirements.txt (line 10)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/site-packages (from onnxruntime-gpu->-r requirements.txt (line 10)) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/site-packages (from onnxruntime-gpu->-r requirements.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: proces>=0.1.7 in /usr/local/lib/python3.9/site-packages (from cn2an->-r requirements.txt (line 13)) (0.1.7)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.9/site-packages (from g2p_en->-r requirements.txt (line 16)) (3.9.1)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.9/site-packages (from g2p_en->-r requirements.txt (line 16)) (7.5.0)\n",
            "Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.9/site-packages (from g2p_en->-r requirements.txt (line 16)) (0.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.9/site-packages (from torch>=1.10.0->torchmetrics==1.5->-r requirements.txt (line 38)) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/site-packages (from sympy->onnxruntime-gpu->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 20)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 20)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.9/site-packages (from transformers->-r requirements.txt (line 20)) (0.5.3)\n",
            "Requirement already satisfied: fast-langdetect in /usr/local/lib/python3.9/site-packages (from split-lang->-r requirements.txt (line 26)) (0.3.1)\n",
            "Requirement already satisfied: budoux in /usr/local/lib/python3.9/site-packages (from split-lang->-r requirements.txt (line 26)) (0.6.4)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.9/site-packages (from Faster_Whisper->-r requirements.txt (line 27)) (4.5.0)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.9/site-packages (from Faster_Whisper->-r requirements.txt (line 27)) (1.19.2)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.9/site-packages (from Faster_Whisper->-r requirements.txt (line 27)) (14.2.0)\n",
            "Requirement already satisfied: python-mecab-ko-dic in /usr/local/lib/python3.9/site-packages (from python_mecab_ko->-r requirements.txt (line 35)) (2.1.1.post2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.9/site-packages (from fastapi<0.112.2->-r requirements.txt (line 36)) (0.38.6)\n",
            "Requirement already satisfied: einx>=0.3.0 in /usr/local/lib/python3.9/site-packages (from x_transformers->-r requirements.txt (line 37)) (0.3.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.9/site-packages (from x_transformers->-r requirements.txt (line 37)) (0.7.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.29.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.9/site-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/site-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.9/site-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/site-packages (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (3.11.13)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.9/site-packages (from einx>=0.3.0->x_transformers->-r requirements.txt (line 37)) (2.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (4.8.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.9/site-packages (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12)) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.9/site-packages (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12)) (4.9.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.21.0)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.9/site-packages (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16)) (10.6.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.9/site-packages (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16)) (4.4.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (8.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/site-packages (from nltk>=3.2.4->g2p_en->-r requirements.txt (line 16)) (8.1.8)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->modelscope==1.10.0->-r requirements.txt (line 18)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.9/site-packages (from pandas->modelscope==1.10.0->-r requirements.txt (line 18)) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/site-packages (from pooch>=1.0->librosa==0.9.2->-r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.9/site-packages (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.9/site-packages (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.25->modelscope==1.10.0->-r requirements.txt (line 18)) (2.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa==0.9.2->-r requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.9/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (13.9.4)\n",
            "\u001b[33mWARNING: typer 0.15.2 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/site-packages (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 10)) (10.0)\n",
            "Requirement already satisfied: robust-downloader>=0.0.2 in /usr/local/lib/python3.9/site-packages (from fast-langdetect->split-lang->-r requirements.txt (line 26)) (0.0.2)\n",
            "Requirement already satisfied: fasttext-predict>=0.9.2.4 in /usr/local/lib/python3.9/site-packages (from fast-langdetect->split-lang->-r requirements.txt (line 26)) (0.9.2.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.9/site-packages (from openai-whisper->funasr==1.0.27->-r requirements.txt (line 12)) (0.9.0)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.9/site-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 12)) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /usr/local/lib/python3.9/site-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 12)) (3.21.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.9/site-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 12)) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.9/site-packages (from oss2->funasr==1.0.27->-r requirements.txt (line 12)) (2.16.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.9/site-packages (from umap-learn->funasr==1.0.27->-r requirements.txt (line 12)) (0.5.13)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.9/site-packages (from yapf->modelscope==1.10.0->-r requirements.txt (line 18)) (2.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (5.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.9/site-packages (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18)) (1.18.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.9/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.9/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12)) (41.0.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (2.21)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.23.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2.19.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/site-packages (from robust-downloader>=0.0.2->fast-langdetect->split-lang->-r requirements.txt (line 26)) (6.9.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (0.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libsox-dev is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Requirement already satisfied: LangSegment in /usr/local/lib/python3.9/site-packages (0.3.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.9/site-packages (from LangSegment) (1.23.4)\n",
            "Requirement already satisfied: py3langid>=0.2.2 in /usr/local/lib/python3.9/site-packages (from LangSegment) (0.3.0)\n",
            "Collecting numpy>=1.19.5 (from LangSegment)\n",
            "  Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.4\n",
            "    Uninstalling numpy-1.23.4:\n",
            "      Successfully uninstalled numpy-1.23.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 4.24.0 requires numpy~=1.0, but you have numpy 2.0.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 2.0.2 which is incompatible.\n",
            "torchmetrics 1.5.0 requires numpy<2.0,>1.20.0, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.0.2\n",
            "Collecting numpy==1.23.4\n",
            "  Using cached numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Using cached numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "py3langid 0.3.0 requires numpy>=2.0.0; python_version >= \"3.9\", but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'tools/damo_asr/speech_fsmn_vad_zh-cn-16k-common-pytorch': No such file or directory\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'tools/damo_asr/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch': No such file or directory\n",
            "mv: cannot stat 'tools/damo_asr/punc_ct-transformer_zh-cn-common-vocab272727-pytorch': No such file or directory\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.9/site-packages (6.29.5)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.9/site-packages (from ipykernel) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.9/site-packages (from ipykernel) (1.8.13)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.9/site-packages (from ipykernel) (8.18.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.9/site-packages (from ipykernel) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.9/site-packages (from ipykernel) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.9/site-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/site-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from ipykernel) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from ipykernel) (7.0.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/lib/python3.9/site-packages (from ipykernel) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.9/site-packages (from ipykernel) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.9/site-packages (from ipykernel) (5.14.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (3.0.50)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (8.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.21.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
            "/content/GPT-SoVITS-v3\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d694e94a0cf91316b7.gradio.live\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/inference_webui.py \"zh_CN\"\n",
            "loading sovits_v3 <All keys matched successfully>\n",
            "Running on local URL:  http://0.0.0.0:8000\n",
            "Running on public URL: https://275de53cddbd1e95b6.gradio.live\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/queueing.py\", line 522, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/route_utils.py\", line 260, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/blocks.py\", line 1689, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/blocks.py\", line 1267, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/utils.py\", line 574, in async_iteration\n",
            "    return await iterator.__anext__()\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/utils.py\", line 567, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 962, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/utils.py\", line 550, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/utils.py\", line 733, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/inference_webui.py\", line 512, in get_tts_wav\n",
            "    if (prompt_text[-1] not in splits): prompt_text += \"„ÄÇ\" if prompt_language != \"en\" else \".\"\n",
            "IndexError: string index out of range\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/queueing.py\", line 522, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/route_utils.py\", line 260, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/blocks.py\", line 1689, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/blocks.py\", line 1267, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/utils.py\", line 574, in async_iteration\n",
            "    return await iterator.__anext__()\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/utils.py\", line 567, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 2461, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 962, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/utils.py\", line 550, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/utils.py\", line 733, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "  File \"/content/GPT-SoVITS-v3/GPT_SoVITS/inference_webui.py\", line 512, in get_tts_wav\n",
            "    if (prompt_text[-1] not in splits): prompt_text += \"„ÄÇ\" if prompt_language != \"en\" else \".\"\n",
            "IndexError: string index out of range\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå¨Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÊàëÊù•ËØïËØï\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÊàëÊù•ËØïËØï\n",
            "ÂΩìÂâç‰ΩøÁî®g2pwËøõË°åÊãºÈü≥Êé®ÁêÜ\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba_fast:Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /content/GPT-SoVITS-v3/TEMP/jieba.cache\n",
            "DEBUG:jieba_fast:Loading model from cache /content/GPT-SoVITS-v3/TEMP/jieba.cache\n",
            "Loading model cost 0.775 seconds.\n",
            "DEBUG:jieba_fast:Loading model cost 0.775 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "DEBUG:jieba_fast:Prefix dict has been built succesfully.\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÊàëÊù•ËØïËØï„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÊàëÊù•ËØïËØï.\n",
            "  1% 19/1500 [00:00<00:32, 45.70it/s]T2S Decoding EOS [239 -> 264]\n",
            "  2% 24/1500 [00:00<00:38, 38.54it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "2.106\t7.260\t0.639\t4.184\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå¨Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÁÉ≠‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ\n",
            "‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÁÉ≠‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): Â§ßÂÆ∂Â•ΩÂìà,‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®Âßê,Â§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫Ü,ÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø.\n",
            " 10% 149/1500 [00:01<00:13, 100.69it/s]T2S Decoding EOS [239 -> 399]\n",
            " 11% 159/1500 [00:01<00:13, 97.94it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÁÉ≠‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰ø∫Ëøô‰∫∫Âêß,Ë¥ºÊãâÂÆûÂú®,ÊúâÂï•ËØ¥Âï•,‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø.‰ø∫ËøôÊÄßÊ†ºÂêß,Â∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑ,ÁÉ≠‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫Ü,ÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø.\n",
            " 18% 266/1500 [00:03<00:13, 94.14it/s]T2S Decoding EOS [239 -> 510]\n",
            " 18% 270/1500 [00:03<00:15, 78.17it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.364\t4.517\t5.085\t17.713\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå¨Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÁÉ≠‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ\n",
            "‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÁÉ≠‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): Â§ßÂÆ∂Â•ΩÂìà,‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®Âßê,Â§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫Ü,ÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø.\n",
            "  9% 142/1500 [00:01<00:13, 102.41it/s]T2S Decoding EOS [239 -> 386]\n",
            " 10% 146/1500 [00:01<00:13, 100.42it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÁÉ≠‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰ø∫Ëøô‰∫∫Âêß,Ë¥ºÊãâÂÆûÂú®,ÊúâÂï•ËØ¥Âï•,‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø.‰ø∫ËøôÊÄßÊ†ºÂêß,Â∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑ,ÁÉ≠‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫Ü,ÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø.\n",
            " 20% 297/1500 [00:02<00:11, 101.04it/s]T2S Decoding EOS [239 -> 539]\n",
            " 20% 299/1500 [00:02<00:11, 101.81it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.351\t2.941\t4.397\t9.754\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå¨Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÂ§ú‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ\n",
            "‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÂ§ú‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): Â§ßÂÆ∂Â•ΩÂìàÔºå‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®ÂßêÔºåÂ§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫ÜÔºåÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): Â§ßÂÆ∂Â•ΩÂìà,‰ø∫ÊòØ‰∏úÂåóÈÇ£ÂòéËææÁöÑÈõ®Âßê,Â§ßÂêçÂÑøÂ∞±‰∏çÊèê‰∫Ü,ÂèçÊ≠£‰∏ÄÊèê‰Ω†‰ª¨‰πüÂæóÊáµÂúàÂÑø.\n",
            " 10% 145/1500 [00:01<00:16, 84.29it/s]T2S Decoding EOS [239 -> 389]\n",
            " 10% 149/1500 [00:01<00:14, 96.38it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰ø∫Ëøô‰∫∫ÂêßÔºåË¥ºÊãâÂÆûÂú®ÔºåÊúâÂï•ËØ¥Âï•Ôºå‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø„ÄÇ‰ø∫ËøôÊÄßÊ†ºÂêßÔºåÂ∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑÔºåÂ§ú‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫ÜÔºåÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰ø∫Ëøô‰∫∫Âêß,Ë¥ºÊãâÂÆûÂú®,ÊúâÂï•ËØ¥Âï•,‰ªé‰∏çÊï¥ÈÇ£‰∫õËôöÂ§¥Â∑¥ËÑëÁöÑÁé©ÊÑèÂÑø.‰ø∫ËøôÊÄßÊ†ºÂêß,Â∞±Ë∑üÂí±‰∏úÂåóÁöÑÂ§©Ê∞î‰ººÁöÑ,Â§ú‰πéËµ∑Êù•ËÉΩÊää‰Ω†ÁÉ§Âåñ‰∫Ü,ÂÜ∑Ëµ∑Êù•‰πüËÉΩËÆ©‰Ω†ÂìÜÂó¶ÊàêÂÜ∞Ê£çÂÑø.\n",
            " 18% 268/1500 [00:02<00:11, 104.11it/s]T2S Decoding EOS [239 -> 510]\n",
            " 18% 270/1500 [00:02<00:11, 105.15it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.401\t2.987\t4.120\t9.913\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå¨Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰Ω†ÁûÖÂï•Âïä,ËøõÊù•ÂêßÂ∞±.\n",
            "  1% 21/1500 [00:00<00:14, 101.17it/s]T2S Decoding EOS [239 -> 268]\n",
            "  2% 28/1500 [00:00<00:14, 99.05it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.404\t1.343\t0.286\t1.793\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå¨Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰Ω†ÁûÖÂï•Âïä,ËøõÊù•ÂêßÂ∞±.\n",
            "  3% 43/1500 [00:00<00:13, 104.38it/s]T2S Decoding EOS [239 -> 289]\n",
            "  3% 49/1500 [00:00<00:14, 101.37it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.355\t1.360\t0.486\t1.892\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå¨Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰Ω†ÁûÖÂï•ÂïäÔºåËøõÊù•ÂêßÂ∞±„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰Ω†ÁûÖÂï•Âïä,ËøõÊù•ÂêßÂ∞±.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.349\t1.351\t0.000\t2.230\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÊàëÊù•ËØïËØï\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÊàëÊù•ËØïËØï\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÊàëÊù•ËØïËØï„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÊàëÊù•ËØïËØï.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.363\t1.334\t0.000\t1.863\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºåÂê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºåÂê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºåÂê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "[\u001b[36m2025-03-08 08:09:26,443\u001b[0m][\u001b[32mINFO\u001b[0m] - Downloading https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin to lid.176.bin (125.2M)\u001b[0m\n",
            "INFO:robust_downloader.downloader:Downloading https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin to lid.176.bin (125.2M)\n",
            "100% 125M/125M [00:02<00:00, 55.7MB/s]\n",
            "['‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑ', 'GPT,', 'Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•‰∏çÊôìÂæóÂÜôÂï•ÂèØ‰ª•ÂºÄ.']\n",
            "['zh', 'en', 'zh']\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑG P T,Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•‰∏çÊôìÂæóÂÜôÂï•ÂèØ‰ª•ÂºÄ.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.379\t11.732\t0.000\t7.888\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºåÂê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºå\n",
            "Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºå\n",
            "['‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑ', 'GPT,']\n",
            "['zh', 'en']\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑG P T,\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•‰∏çÊôìÂæóÂÜôÂï•ÂèØ‰ª•ÂºÄ.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨.\n",
            "  4% 54/1500 [00:00<00:14, 102.23it/s]T2S Decoding EOS [239 -> 296]\n",
            "  4% 56/1500 [00:00<00:14, 99.97it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.374\t2.358\t0.563\t9.489\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºåÂê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºå\n",
            "Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºå\n",
            "['‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑ', 'GPT,']\n",
            "['zh', 'en']\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑG P T,\n",
            "  7% 109/1500 [00:01<00:13, 103.03it/s]T2S Decoding EOS [239 -> 355]\n",
            "  8% 115/1500 [00:01<00:13, 102.61it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•‰∏çÊôìÂæóÂÜôÂï•ÂèØ‰ª•ÂºÄ.\n",
            "  4% 66/1500 [00:00<00:16, 84.38it/s]T2S Decoding EOS [239 -> 314]\n",
            "  5% 74/1500 [00:00<00:18, 76.19it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨.\n",
            "  4% 55/1500 [00:00<00:13, 104.31it/s]T2S Decoding EOS [239 -> 302]\n",
            "  4% 62/1500 [00:00<00:14, 101.85it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.361\t2.925\t2.716\t6.064\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºåÂê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºå\n",
            "Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑGPTÔºå\n",
            "['‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑ', 'GPT,']\n",
            "['zh', 'en']\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ‰ΩøÁî®Êó†ÂèÇËÄÉÊñáÊú¨Ê®°ÂºèÊó∂Âª∫ËÆÆ‰ΩøÁî®ÂæÆË∞ÉÁöÑG P T,\n",
            "  6% 88/1500 [00:00<00:14, 99.46it/s]T2S Decoding EOS [239 -> 337]\n",
            "  6% 97/1500 [00:01<00:15, 92.15it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•(‰∏çÊôìÂæóÂÜôÂï•)ÂèØ‰ª•ÂºÄ„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): Âê¨‰∏çÊ∏ÖÂèÇËÄÉÈü≥È¢ëËØ¥ÁöÑÂï•‰∏çÊôìÂæóÂÜôÂï•ÂèØ‰ª•ÂºÄ.\n",
            " 10% 153/1500 [00:01<00:13, 97.46it/s] T2S Decoding EOS [239 -> 401]\n",
            " 11% 161/1500 [00:01<00:13, 99.85it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÂºÄÂêØÂêéÊó†ËßÜÂ°´ÂÜôÁöÑÂèÇËÄÉÊñáÊú¨.\n",
            "  4% 59/1500 [00:00<00:22, 62.71it/s]T2S Decoding EOS [239 -> 301]\n",
            "  4% 61/1500 [00:00<00:22, 63.98it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.654\t2.717\t3.629\t7.912\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞ÂçÅ‰∫îÂ§©ÂæÄ‰∏äÂïä,Ê≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•Ω,ËÆ©ÂÆÉÂèëÈÖµÂ•Ω,ÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïä,Ëøô‰∏™Ëå∂Â≠ê.\n",
            " 14% 215/1500 [00:03<00:16, 76.59it/s]T2S Decoding EOS [239 -> 462]\n",
            " 15% 222/1500 [00:03<00:19, 66.82it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.398\t3.626\t3.326\t4.181\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•Âïä,Áõ¥Êé•ËøõÊù•Âêß.\n",
            "  9% 140/1500 [00:01<00:13, 101.85it/s]T2S Decoding EOS [239 -> 388]\n",
            " 10% 148/1500 [00:01<00:13, 99.45it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.366\t1.441\t1.491\t4.039\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•Âïä,Áõ¥Êé•ËøõÊù•Âêß.\n",
            " 10% 148/1500 [00:01<00:13, 99.82it/s] T2S Decoding EOS [239 -> 392]\n",
            " 10% 152/1500 [00:01<00:13, 98.48it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.369\t1.430\t1.546\t3.778\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•Âïä,Áõ¥Êé•ËøõÊù•Âêß.\n",
            " 10% 150/1500 [00:01<00:13, 100.50it/s]T2S Decoding EOS [239 -> 392]\n",
            " 10% 152/1500 [00:01<00:13, 98.80it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.680\t2.527\t1.542\t3.786\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•Âïä,Áõ¥Êé•ËøõÊù•Âêß.\n",
            "  4% 65/1500 [00:00<00:14, 100.84it/s]T2S Decoding EOS [239 -> 306]\n",
            "  4% 66/1500 [00:00<00:14, 98.48it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.467\t2.843\t0.673\t2.007\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•Âïä,Áõ¥Êé•ËøõÊù•Âêß.\n",
            "  3% 43/1500 [00:00<00:14, 102.61it/s]T2S Decoding EOS [239 -> 290]\n",
            "  3% 50/1500 [00:00<00:14, 99.61it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.377\t1.451\t0.505\t1.940\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•ÂïäÔºåÁõ¥Êé•ËøõÊù•Âêß„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÈÇ£ËøòÂú®Â§ñÈù¢ÁûÖÂï•Âïä,Áõ¥Êé•ËøõÊù•Âêß.\n",
            "  4% 64/1500 [00:00<00:13, 103.26it/s]T2S Decoding EOS [239 -> 307]\n",
            "  4% 67/1500 [00:00<00:14, 101.41it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.379\t1.426\t0.664\t1.976\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: Ëá™ÂÆö‰πâÂ£∞Èü≥Ê®°Âºè‰∏ãÔºå‰∏∫‰øùËØÅËØ≠Èü≥Ë¥®ÈáèÔºåÊØèÊ¨°ÁîüÊàêËØ∑ÈôêÂà∂Âú®200Â≠ó‰ª•ÂÜÖ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): Ëá™ÂÆö‰πâÂ£∞Èü≥Ê®°Âºè‰∏ãÔºå‰∏∫‰øùËØÅËØ≠Èü≥Ë¥®ÈáèÔºåÊØèÊ¨°ÁîüÊàêËØ∑ÈôêÂà∂Âú®200Â≠ó‰ª•ÂÜÖ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): Ëá™ÂÆö‰πâÂ£∞Èü≥Ê®°Âºè‰∏ãÔºå‰∏∫‰øùËØÅËØ≠Èü≥Ë¥®ÈáèÔºåÊØèÊ¨°ÁîüÊàêËØ∑ÈôêÂà∂Âú®200Â≠ó‰ª•ÂÜÖ„ÄÇ\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): Ëá™ÂÆö‰πâÂ£∞Èü≥Ê®°Âºè‰∏ã,‰∏∫‰øùËØÅËØ≠Èü≥Ë¥®Èáè,ÊØèÊ¨°ÁîüÊàêËØ∑ÈôêÂà∂Âú®‰∫åÈõ∂Èõ∂Â≠ó‰ª•ÂÜÖ.\n",
            "  9% 131/1500 [00:01<00:13, 104.78it/s]T2S Decoding EOS [239 -> 380]\n",
            "  9% 140/1500 [00:01<00:13, 102.29it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.372\t1.585\t1.372\t3.717\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÂìéÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÂìéÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÂìéÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÂìéÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  2% 32/1500 [00:00<00:14, 104.33it/s]T2S Decoding EOS [239 -> 282]\n",
            "  3% 42/1500 [00:00<00:14, 100.06it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.367\t1.443\t0.423\t1.811\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 43/1500 [00:00<00:14, 102.73it/s]T2S Decoding EOS [239 -> 288]\n",
            "  3% 48/1500 [00:00<00:14, 100.59it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.681\t1.641\t0.480\t1.875\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 39/1500 [00:00<00:15, 94.72it/s]T2S Decoding EOS [239 -> 283]\n",
            "  3% 43/1500 [00:00<00:16, 90.54it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.395\t2.868\t0.479\t1.822\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 38/1500 [00:00<00:21, 66.87it/s]T2S Decoding EOS [239 -> 285]\n",
            "  3% 45/1500 [00:00<00:22, 65.87it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.397\t1.392\t0.686\t2.322\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 43/1500 [00:00<00:14, 97.87it/s] T2S Decoding EOS [239 -> 285]\n",
            "  3% 45/1500 [00:00<00:15, 96.32it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.359\t1.421\t0.470\t2.127\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 43/1500 [00:00<00:14, 103.59it/s]T2S Decoding EOS [239 -> 283]\n",
            "  3% 43/1500 [00:00<00:14, 100.49it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.385\t1.387\t0.431\t2.018\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  4% 53/1500 [00:00<00:14, 101.46it/s]T2S Decoding EOS [239 -> 297]\n",
            "  4% 57/1500 [00:00<00:14, 96.36it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.657\t2.197\t0.595\t1.912\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  4% 53/1500 [00:00<00:14, 97.94it/s]T2S Decoding EOS [239 -> 299]\n",
            "  4% 59/1500 [00:00<00:14, 96.09it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.373\t1.381\t0.617\t3.277\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 43/1500 [00:00<00:14, 100.30it/s]T2S Decoding EOS [239 -> 287]\n",
            "  3% 47/1500 [00:00<00:14, 97.05it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.370\t1.391\t0.495\t2.928\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 46/1500 [00:00<00:21, 68.47it/s]T2S Decoding EOS [239 -> 287]\n",
            "  3% 47/1500 [00:00<00:21, 66.71it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.354\t1.441\t0.708\t3.449\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 40/1500 [00:00<00:14, 97.50it/s]T2S Decoding EOS [239 -> 285]\n",
            "  3% 45/1500 [00:00<00:15, 93.99it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.517\t2.656\t0.482\t2.976\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 40/1500 [00:00<00:15, 96.03it/s]T2S Decoding EOS [239 -> 285]\n",
            "  3% 45/1500 [00:00<00:15, 92.08it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.534\t1.414\t0.492\t2.938\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  3% 49/1500 [00:00<00:18, 79.75it/s]T2S Decoding EOS [239 -> 290]\n",
            "  3% 50/1500 [00:00<00:19, 74.45it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.383\t1.974\t0.682\t3.517\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÂèÇËÄÉÊñáÊú¨: ÂïäÊ≠£Â∏∏Ëøô‰∏™Ëå¨Â≠ê‰Ω†ÂæóÊ≥°Âà∞15Â§©ÂæÄ‰∏äÂïäÔºåÊ≥°ÁöÑÊó∂Èó¥Ë∂äÈïøË∂äÂ•ΩÔºåËÆ©ÂÆÉÂèëÈÖµÂ•ΩÔºåÈÇ£Ê†∑ÁöÑÈù¢Â≠êÊëûÂá∫Êù•ÁöÑÈ•ºÈÇ£ÊòØÂìèÂïæÁöÑÂïäÔºåËøô‰∏™Ëå∂Â≠ê„ÄÇ\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨: ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÂàáÂè•Âêé): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂÆûÈôÖËæìÂÖ•ÁöÑÁõÆÊ†áÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞ÔºåÊù•‰∫ÜÂïäÔºü\n",
            "ÂâçÁ´ØÂ§ÑÁêÜÂêéÁöÑÊñáÊú¨(ÊØèÂè•): ÁôåÂëÄÂ¶àÊ£ÆÊé∞,Êù•‰∫ÜÂïä?\n",
            "  4% 58/1500 [00:00<00:19, 73.23it/s]T2S Decoding EOS [239 -> 300]\n",
            "  4% 60/1500 [00:00<00:21, 67.27it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.351\t1.797\t0.895\t3.941\n"
          ]
        }
      ],
      "source": [
        "# @title ‰∏ÄÈîÆÂºÄÂêØGPT-SoVITS-v3\n",
        "\n",
        "!pip install -q condacolab\n",
        "# Setting up condacolab and installing packages\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/miniconda/Miniconda3-py39_23.11.0-2-Linux-x86_64.sh\")\n",
        "!git clone https://huggingface.co/kevinwang676/GPT-SoVITS-v3.git\n",
        "!conda install -y -q -c pytorch -c nvidia cudatoolkit\n",
        "%cd GPT-SoVITS-v3\n",
        "!conda install -y -q -c conda-forge gcc gxx ffmpeg cmake -c pytorch -c nvidia\n",
        "!/usr/local/bin/pip install -r requirements.txt\n",
        "!sudo apt install ffmpeg\n",
        "!sudo apt install libsox-dev\n",
        "!pip install LangSegment\n",
        "!pip install numpy==1.23.4\n",
        "import nltk\n",
        "nltk.download(\"all\")\n",
        "!mv tools/damo_asr/speech_fsmn_vad_zh-cn-16k-common-pytorch tools/asr/models/\n",
        "!mv tools/damo_asr/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch tools/asr/models/\n",
        "!mv tools/damo_asr/punc_ct-transformer_zh-cn-common-vocab272727-pytorch tools/asr/models/\n",
        "!/usr/local/bin/pip install ipykernel\n",
        "!sed -i '10s/False/True/' /content/GPT-SoVITS-v3/config.py\n",
        "%cd /content/GPT-SoVITS-v3/\n",
        "!/usr/local/bin/python webui.py zh_CN"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}